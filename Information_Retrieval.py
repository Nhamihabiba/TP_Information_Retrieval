# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pml8OJrVHd891nuKT6PnzPVsoKfSs70X
"""

import os
from bs4 import BeautifulSoup
import requests
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from collections import defaultdict

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# Etape 1: Construction d'un corpus de documents sur le Covid-19
urls = [
    "https://www.nature.com/articles/d41586-020-00502-w",
    "https://www.nejm.org/doi/full/10.1056/NEJMoa2033700?query-featured_coronavirus=",
    "https://www.nejm.org/doi/full/10.1056/NEJMoa2030340?query=featured_coronavirus",
    "https://www.nejm.org/doi/full/10.1056/NEJMoa2035002?query-featured_coronavirus=",
    "https://www.nejm.org/doi/full/10.1056/NEJMoa2029849?query=featured_coronavirus",
    "https://www.nejm.org/doi/full/10.1056/NEJMpv2035416?query=featured_coronavirus",
    "https://www.thelancet.com/journals/lanrhe/article/PIIS2665-9913(21)00007-2/fulltext",
    "https://www.thelancet.com/journals/lanres/article/PIIS2213-2600(21)00025-4/fulltext",
    "https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)32656-8/fulltext",
    "https://science.sciencemag.org/content/early/2021/01/11/science.abe6522"
]

corpus_directory = "corpus"
if not os.path.exists(corpus_directory):
    os.makedirs(corpus_directory)

for idx, url in enumerate(urls):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    text = soup.get_text()
    with open(os.path.join(corpus_directory, f"document_{idx+1}.txt"), "w") as f:
        f.write(text)

# Etape 2: Pre-traitement des données et construction de la matrice d'incidence
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
dictionary = set()

# Dictionnaire pour stocker la matrice d'incidence
incidence_matrix = defaultdict(lambda: defaultdict(int))

# Parcours du corpus
for file_name in os.listdir(corpus_directory):
    with open(os.path.join(corpus_directory, file_name), "r") as f:
        text = f.read()
        tokens = word_tokenize(text.lower())
        filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]
        unique_tokens = set(filtered_tokens)
        dictionary.update(unique_tokens)
        for token in unique_tokens:
            incidence_matrix[file_name][token] = filtered_tokens.count(token)

# Etape 3: Construction de l'index inversé
inverted_index = defaultdict(list)
for term in dictionary:
    for document, token_counts in incidence_matrix.items():
        if term in token_counts:
            inverted_index[term].append((document, token_counts[term]))

# Etape 4: Implémentation d'un algorithme de recherche d'information
def boolean_query(query):
    results = set()
    query_tokens = [lemmatizer.lemmatize(token.lower()) for token in word_tokenize(query) if token.isalnum() and token not in stop_words]
    for token in query_tokens:
        if token in inverted_index:
            results.update([doc for doc, _ in inverted_index[token]])
    return results

# Requêtes booléennes
queries = [
    "desease AND severe",
    "antibody AND plasma AND (cells OR receptors)",
    "antimalarial drugs OR antiviral agents OR immunomodulators",
    "NOT plasma AND risk of infection AND NOT restrictions",
    "(older adults AND antibodies) AND (genomes OR variant)"
]

for idx, query in enumerate(queries):
    print(f"Query {idx+1}: {query}")
    results = boolean_query(query)
    print(f"Results: {results}\n")

# Requêtes textuelles plus complexes
complex_queries = [
    "antibody treatments",
    "efficacy and safety of the treatments",
    "family access to hospitals",
    "contact tracing results",
    "genomic analysis of SARS-CoV-2 disease"
]

for idx, query in enumerate(complex_queries):
    print(f"Complex Query {idx+1}: {query}")
    results = boolean_query(query)
    print(f"Results: {results}\n")

# Exemple de résultats attendus
resultats_attendus = [1, 0, 1, 1, 0]

# Exemple de résultats obtenus par votre algorithme
resultats_obtenus = [1, 0, 1, 1, 1]

# Calculer l'accuarcy
nombre_total = len(resultats_attendus)
nombre_correct = sum(1 for attendu, obtenu in zip(resultats_attendus, resultats_obtenus) if attendu == obtenu)
accuarcy = nombre_correct / nombre_total

# Afficher l'accuarcy
print("L'accuarcy est : {:.2f}%".format(accuarcy * 100))